{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2dd98075",
   "metadata": {},
   "source": [
    "## Hans Tausen iskappe in Greenland\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "581efa1f",
   "metadata": {},
   "source": [
    "first we need to import some libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1f5ec60f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# general libraries\n",
    "\n",
    "import os\n",
    "import urllib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from scipy import ndimage\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ab5a1108",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import functions from specific libraries\n",
    "from eratosthenes.generic.mapping_io import \\\n",
    "    read_geo_image, read_geo_info, make_geo_im\n",
    "from eratosthenes.generic.mapping_tools import \\\n",
    "    pix_centers\n",
    "from eratosthenes.generic.handler_im import get_grad_filters\n",
    "from eratosthenes.generic.gis_tools import get_mask_boundary\n",
    "from eratosthenes.preprocessing.image_transforms import \\\n",
    "    gamma_adjustment, mat_to_gray\n",
    "from eratosthenes.preprocessing.shadow_filters import \\\n",
    "    anistropic_diffusion_scalar\n",
    "from eratosthenes.postprocessing.displacement_filters import \\\n",
    "    local_infilling_filter\n",
    "from eratosthenes.postprocessing.terrain_tools import d8_flow\n",
    "from eratosthenes.presentation.terrain_tools import curvature_enhanced_shading\n",
    "from eratosthenes.presentation.image_io import output_image, output_mask\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcb1a58c-0966-4cd7-a88b-e2f7b3df26a5",
   "metadata": {},
   "source": [
    "The data is situated on a drive, but these can be downloaded to a local drive. Hence the following code sniplet looks if such data is already available, if not it is downloaded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3f2299a4-6317-4c01-aeed-6dcafc5ccd6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "files are already present\n"
     ]
    }
   ],
   "source": [
    "# admin\n",
    "dat_dir = '/Users/Alten005/icedivide'\n",
    "dat_url = 'https://surfdrive.surf.nl/files/index.php/s/qebmYP7idEW89O0'\n",
    "\n",
    "vel_name = 'greenlan_iv_100m_s1_insar_s20181201_e20210301_v1_'\n",
    "v_x_name, v_y_name = 'east_velo.tif', 'north_velo.tif'\n",
    "v_x_std, v_y_std = 'east_std.tif', 'north_std.tif'\n",
    "v_count = 'count.tif'\n",
    "rgi_name = 'glacier_ids.tif'\n",
    "dem_name = 'arcticdem_100m.tif'\n",
    "\n",
    "# do downloading if files are not present\n",
    "if not os.path.exists(os.path.join(dat_dir, rgi_name)):\n",
    "    file_grab = urllib.URLopener()\n",
    "    print('busy downloading files')\n",
    "    # dowload velocity data\n",
    "    file_grab.retrieve(os.path.join(dat_url, vel_name + v_x_name),\n",
    "                       os.path.join(dat_dir, vel_name + v_x_name))\n",
    "    file_grab.retrieve(os.path.join(dat_url, vel_name + v_y_name),\n",
    "                       os.path.join(dat_dir, vel_name + v_y_name))\n",
    "    file_grab.retrieve(os.path.join(dat_url, vel_name + v_x_std),\n",
    "                       os.path.join(dat_dir, vel_name + v_x_std))\n",
    "    file_grab.retrieve(os.path.join(dat_url, vel_name + v_y_std),\n",
    "                       os.path.join(dat_dir, vel_name + v_y_std))\n",
    "    file_grab.retrieve(os.path.join(dat_url, vel_name + v_count),\n",
    "                       os.path.join(dat_dir, vel_name + v_count))\n",
    "    # download auxillary data\n",
    "    file_grab.retrieve(os.path.join(dat_url, rgi_name),\n",
    "                       os.path.join(dat_dir, rgi_name))\n",
    "    file_grab.retrieve(os.path.join(dat_url, dem_name),\n",
    "                       os.path.join(dat_dir, dem_name))\n",
    "    print('files dowloaded')\n",
    "else:\n",
    "    print('files are already present')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27209e8b-bb94-4d9b-b0f2-38520baf394c",
   "metadata": {},
   "source": [
    "import rasters with glacier polygons (RGI) and elevation (Z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8c7fffd8-0523-4a94-8aae-cd98c7f61efa",
   "metadata": {},
   "outputs": [],
   "source": [
    "spatialRef, geoTransform,_,_,_,_ = read_geo_info(\n",
    "    os.path.join(dat_dir, rgi_name))\n",
    "RGI = read_geo_image(os.path.join(dat_dir, rgi_name))[0]\n",
    "Z = read_geo_image(os.path.join(dat_dir, dem_name))[0]\n",
    "RGI[RGI==1], Z[Z==-9999] = 0, np.nan\n",
    "X,Y = pix_centers(geoTransform, Z.shape[0], Z.shape[1], make_grid=True)\n",
    "spac = np.sqrt(np.sum(np.asarray(geoTransform[1:3])**2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc69054c-7e74-473d-a5f2-95fea09fac3d",
   "metadata": {},
   "source": [
    "import velocity products"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d8e7113e-1b6e-4575-a947-b8c1ca42b991",
   "metadata": {},
   "outputs": [],
   "source": [
    "V_x = read_geo_image(os.path.join(dat_dir, vel_name + v_x_name))[0]\n",
    "V_y = read_geo_image(os.path.join(dat_dir, vel_name + v_y_name))[0]\n",
    "V_x_std = read_geo_image(os.path.join(dat_dir, vel_name + v_y_std))[0]\n",
    "V_y_std = read_geo_image(os.path.join(dat_dir, vel_name + v_y_std))[0]\n",
    "V_count = read_geo_image(os.path.join(dat_dir, vel_name + v_count))[0]\n",
    "\n",
    "NaN_val = V_x[0][0]\n",
    "V_x[V_x==NaN_val], V_y[V_y==NaN_val] = np.nan, np.nan\n",
    "V_x_std[V_x_std==NaN_val], V_y_std[V_y_std==NaN_val] = np.nan, np.nan"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6b7c5c4-6edd-447f-87f7-36c266d7e7bc",
   "metadata": {},
   "source": [
    "make topographic gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d20a03a4-e178-4cf7-90a3-79df098b22d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "fx,fy = get_grad_filters(ftype='kroon', tsize=3, order=1)\n",
    "Z_x, Z_y = ndimage.convolve(Z, fx), ndimage.convolve(Z, fy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a15526c1-2fd7-4389-9c1a-14f0818ffe7a",
   "metadata": {},
   "source": [
    "filling of the velocity field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1e6d7ebe-e061-4b7d-8440-6a2c82759efd",
   "metadata": {},
   "outputs": [],
   "source": [
    "V_x_fill = local_infilling_filter(V_x, tsize=5)\n",
    "V_y_fill = local_infilling_filter(V_y, tsize=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d08a3938-8aea-4882-ae82-d13973162a67",
   "metadata": {},
   "source": [
    "cleaning of the velocity field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c122a188-015e-46f5-a01d-5c40e50476b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "V_clean = anistropic_diffusion_scalar(np.dstack((V_x_fill, V_y_fill)), iter=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd658a3c-d459-4a8e-a297-d8426c921f04",
   "metadata": {},
   "source": [
    "d8 implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a9e452f8-b486-44cd-8ddd-c0a50c718e3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "RGI_new = d8_flow(RGI, -1*V_clean[:,:,0], +1*V_clean[:,:,1], iter=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3749795e-8434-4377-a009-32016dbb031d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
